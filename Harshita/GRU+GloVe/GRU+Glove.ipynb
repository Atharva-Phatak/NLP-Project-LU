{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GRU+Glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYVAUCyZpzk4"
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import Dense, GRU, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8WC7ACVNFBE",
        "outputId": "8fa9001f-f16e-455e-cc7f-14c33e9d4bcb"
      },
      "source": [
        "#Mount drive to access files in gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQn9vBzRp_Mu"
      },
      "source": [
        "# Read Train, Test and Gold dataset\n",
        "df_train = pd.read_csv(\"/content/gdrive/MyDrive/NLP_Project/train.csv\")\n",
        "df_test = pd.read_csv(\"/content/gdrive/MyDrive/NLP_Project/dev.csv\")\n",
        "df_gold = pd.read_csv(\"/content/gdrive/MyDrive/NLP_Project/gold-test.csv\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5byNkGwqMz9"
      },
      "source": [
        "# Function removing tags\n",
        "def remove_tags(string):\n",
        "    result = re.sub('<.*?>','',string)\n",
        "    return result"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9nonJ7VdKUq"
      },
      "source": [
        "# Preprocessing data lowercase and removing hyperlinks\n",
        "def preProcessData(data_frame):\n",
        "    data_frame['text'] = (data_frame['text']).str.lower()\n",
        "    data_frame['text'] = data_frame['text'].apply(lambda cw : remove_tags(cw))\n",
        "    return data_frame"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKsTJ5FynO2u"
      },
      "source": [
        "# Creating train, test and gold labels\n",
        "X_train = preProcessData(df_train)['text']\n",
        "X_test = preProcessData(df_test)['text']\n",
        "X_gold = preProcessData(df_gold)['text']\n",
        "Y_train = df_train['is_humor']\n",
        "Y_test = df_test['is_humor']\n",
        "Y_gold = df_gold['is_humor']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwWPPtH2x5L9"
      },
      "source": [
        "# Tokenizing the sentences and adding padding\n",
        "vocabulary_size = 20000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "seq_matrix_train = pad_sequences(sequences_train, maxlen=200)\n",
        "\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "seq_matrix_test = pad_sequences(sequences_test, maxlen= 200)\n",
        "\n",
        "sequences_gold = tokenizer.texts_to_sequences(X_gold)\n",
        "seq_matrix_gold = pad_sequences(sequences_gold, maxlen= 200)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFIeklYtyG5s",
        "outputId": "4cfba0b7-f448-4a31-b967-eb67803fb16d"
      },
      "source": [
        "# Reading GloVe Embeddings\n",
        "embeddings_index = dict()\n",
        "f = open('/content/gdrive/MyDrive/NLP_Project/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnWzssSNyTnx"
      },
      "source": [
        "# Creating weight matrix \n",
        "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ0l8xHCytD-"
      },
      "source": [
        "# Metrics to evaluate model\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SV_k8ZJyaX3",
        "outputId": "670021c5-9ec8-468e-ec70-c5efd295fcac"
      },
      "source": [
        "%%time\n",
        "# Initializing Model \n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, 300, input_length=50, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy',f1_m, precision_m, recall_m])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 50, 300)           6000000   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 50, 300)           0         \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 100)               120600    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 6,120,701\n",
            "Trainable params: 120,701\n",
            "Non-trainable params: 6,000,000\n",
            "_________________________________________________________________\n",
            "CPU times: user 458 ms, sys: 41.5 ms, total: 500 ms\n",
            "Wall time: 456 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pINu3QDgfMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b289c39-fa50-4f9e-9dc6-dfaf418ef499"
      },
      "source": [
        "%%time\n",
        "# Training the model\n",
        "model_glove.fit(seq_matrix_train, df_train['is_humor'], epochs = 10, batch_size= 128)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 50) for input KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 50) for input KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "63/63 [==============================] - 4s 26ms/step - loss: 0.1320 - binary_accuracy: 0.9475 - f1_m: 0.9572 - precision_m: 0.9574 - recall_m: 0.9578\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.1071 - binary_accuracy: 0.9619 - f1_m: 0.9688 - precision_m: 0.9682 - recall_m: 0.9703\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0937 - binary_accuracy: 0.9663 - f1_m: 0.9726 - precision_m: 0.9700 - recall_m: 0.9757\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0852 - binary_accuracy: 0.9736 - f1_m: 0.9781 - precision_m: 0.9781 - recall_m: 0.9783\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.0827 - binary_accuracy: 0.9709 - f1_m: 0.9755 - precision_m: 0.9783 - recall_m: 0.9735\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0657 - binary_accuracy: 0.9763 - f1_m: 0.9807 - precision_m: 0.9838 - recall_m: 0.9779\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0595 - binary_accuracy: 0.9766 - f1_m: 0.9807 - precision_m: 0.9807 - recall_m: 0.9808\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.0478 - binary_accuracy: 0.9841 - f1_m: 0.9873 - precision_m: 0.9871 - recall_m: 0.9877\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.0511 - binary_accuracy: 0.9833 - f1_m: 0.9862 - precision_m: 0.9873 - recall_m: 0.9854\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.0308 - binary_accuracy: 0.9911 - f1_m: 0.9929 - precision_m: 0.9933 - recall_m: 0.9926\n",
            "CPU times: user 16.7 s, sys: 624 ms, total: 17.4 s\n",
            "Wall time: 17.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4b3f662e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkFCtvYgcJnK",
        "outputId": "4ca8d03f-bad3-4a11-85e2-c34621c218dd"
      },
      "source": [
        "# Evaluating model for gold and test data\n",
        "gold_accuracy = model_glove.evaluate(seq_matrix_gold, Y_gold)\n",
        "test_accuracy = model_glove.evaluate(seq_matrix_test, Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n F1 Score:{:0.3f}'.format(test_accuracy[0],test_accuracy[1]*100, test_accuracy[2]))\n",
        "print('Gold set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n F1 Score:{:0.3f}'.format(gold_accuracy[0],gold_accuracy[1]*100, gold_accuracy[2]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 50) for input KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "32/32 [==============================] - 1s 10ms/step - loss: 0.6279 - binary_accuracy: 0.8380 - f1_m: 0.8669 - precision_m: 0.8832 - recall_m: 0.8584\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.6253 - binary_accuracy: 0.8430 - f1_m: 0.8753 - precision_m: 0.8698 - recall_m: 0.8868\n",
            "Test set\n",
            "  Loss: 0.625\n",
            "  Accuracy: 84.300\n",
            " F1 Score:0.875\n",
            "Gold set\n",
            "  Loss: 0.628\n",
            "  Accuracy: 83.800\n",
            " F1 Score:0.867\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}