{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GRU+Glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYVAUCyZpzk4"
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import Dense, GRU, Dropout, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8WC7ACVNFBE",
        "outputId": "80468f20-0179-445e-cf1f-19457280f599"
      },
      "source": [
        "#Mount drive to access files in gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQn9vBzRp_Mu"
      },
      "source": [
        "# Read Train, Test and Gold dataset\n",
        "df_train = pd.read_csv(\"/content/gdrive/MyDrive/NLP_Project/train.csv\")\n",
        "df_test = pd.read_csv(\"/content/gdrive/MyDrive/NLP_Project/dev.csv\")\n",
        "df_gold = pd.read_csv(\"/content/gdrive/MyDrive/NLP_Project/gold-test.csv\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9nonJ7VdKUq"
      },
      "source": [
        "# Preprocessing data lowercase and removing hyperlinks\n",
        "def preProcessData(data_frame):\n",
        "    data_frame['text'] = (data_frame['text']).str.lower()\n",
        "    data_frame['text'] = data_frame['text'].apply(lambda x: re.sub(r\"^https?:\\/\\/.*[\\r\\n]*\", \"\", x, flags=re.MULTILINE))\n",
        "    return data_frame"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKsTJ5FynO2u"
      },
      "source": [
        "# Creating train, test and gold labels\n",
        "X_train = preProcessData(df_train)['text']\n",
        "X_test = preProcessData(df_test)['text']\n",
        "X_gold = preProcessData(df_gold)['text']\n",
        "Y_train = df_train['is_humor']\n",
        "Y_test = df_test['is_humor']\n",
        "Y_gold = df_gold['is_humor']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwWPPtH2x5L9"
      },
      "source": [
        "# Tokenizing the sentences and adding padding\n",
        "vocabulary_size = 20000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "seq_matrix_train = pad_sequences(sequences_train, maxlen=200)\n",
        "\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "seq_matrix_test = pad_sequences(sequences_test, maxlen= 200)\n",
        "\n",
        "sequences_gold = tokenizer.texts_to_sequences(X_gold)\n",
        "seq_matrix_gold = pad_sequences(sequences_gold, maxlen= 200)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFIeklYtyG5s",
        "outputId": "7fa1b4d0-6fc3-49af-ad37-53728430d60e"
      },
      "source": [
        "# Reading GloVe Embeddings\n",
        "embeddings_index = dict()\n",
        "f = open('/content/gdrive/MyDrive/NLP_Project/glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnWzssSNyTnx"
      },
      "source": [
        "# Creating weight matrix \n",
        "embedding_matrix = np.zeros((vocabulary_size, 300))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ0l8xHCytD-"
      },
      "source": [
        "# Metrics to evaluate model\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SV_k8ZJyaX3",
        "outputId": "78530f22-27a1-46be-87b9-fb6cbd6d4ea6"
      },
      "source": [
        "%%time\n",
        "# Initializing Model \n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, 300, input_length=50, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy',f1_m, precision_m, recall_m])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 50, 300)           6000000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50, 300)           0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 100)               120600    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 6,120,701\n",
            "Trainable params: 120,701\n",
            "Non-trainable params: 6,000,000\n",
            "_________________________________________________________________\n",
            "CPU times: user 282 ms, sys: 21.3 ms, total: 304 ms\n",
            "Wall time: 263 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pINu3QDgfMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9729cfeb-1e5c-47c3-bd9e-96ce5e46a6d9"
      },
      "source": [
        "%%time\n",
        "# Training the model\n",
        "model.fit(seq_matrix_train, df_train['is_humor'], epochs = 10, batch_size= 128)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 50) for input KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 50) for input KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name='embedding_2_input'), name='embedding_2_input', description=\"created by layer 'embedding_2_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "63/63 [==============================] - 4s 25ms/step - loss: 0.6006 - binary_accuracy: 0.6613 - f1_m: 0.7441 - precision_m: 0.6802 - recall_m: 0.8357\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.4072 - binary_accuracy: 0.8166 - f1_m: 0.8538 - precision_m: 0.8373 - recall_m: 0.8761\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.3739 - binary_accuracy: 0.8309 - f1_m: 0.8659 - precision_m: 0.8507 - recall_m: 0.8911\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.3274 - binary_accuracy: 0.8565 - f1_m: 0.8852 - precision_m: 0.8743 - recall_m: 0.9009\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.2735 - binary_accuracy: 0.8825 - f1_m: 0.9065 - precision_m: 0.9014 - recall_m: 0.9138\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.2534 - binary_accuracy: 0.8896 - f1_m: 0.9100 - precision_m: 0.9035 - recall_m: 0.9207\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2137 - binary_accuracy: 0.9120 - f1_m: 0.9272 - precision_m: 0.9288 - recall_m: 0.9271\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.2024 - binary_accuracy: 0.9165 - f1_m: 0.9318 - precision_m: 0.9322 - recall_m: 0.9342\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1735 - binary_accuracy: 0.9253 - f1_m: 0.9383 - precision_m: 0.9365 - recall_m: 0.9413\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.1502 - binary_accuracy: 0.9417 - f1_m: 0.9520 - precision_m: 0.9535 - recall_m: 0.9519\n",
            "CPU times: user 17 s, sys: 610 ms, total: 17.6 s\n",
            "Wall time: 17.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1cc8c3ce90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkFCtvYgcJnK",
        "outputId": "88817f3a-ce55-4272-faaf-53b791a5c7f7"
      },
      "source": [
        "# Evaluating model for gold and test data\n",
        "gold_accuracy = model.evaluate(seq_matrix_gold, Y_gold)\n",
        "test_accuracy = model.evaluate(seq_matrix_test, Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n F1 Score:{:0.3f}'.format(test_accuracy[0],test_accuracy[1], test_accuracy[2]))\n",
        "print('Gold set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n F1 Score:{:0.3f}'.format(gold_accuracy[0],gold_accuracy[1], gold_accuracy[2]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3922 - binary_accuracy: 0.8550 - f1_m: 0.8789 - precision_m: 0.9052 - recall_m: 0.8591\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3939 - binary_accuracy: 0.8320 - f1_m: 0.8668 - precision_m: 0.8656 - recall_m: 0.8749\n",
            "Test set\n",
            "  Loss: 0.394\n",
            "  Accuracy: 0.832\n",
            " F1 Score:0.867\n",
            "Gold set\n",
            "  Loss: 0.392\n",
            "  Accuracy: 0.855\n",
            " F1 Score:0.879\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}