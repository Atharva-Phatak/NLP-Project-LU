{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Humor_Detection_Augemented_Data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUEtkD1i0NHI",
        "outputId": "9c7be9ca-3161-4f6f-b4aa-e3ccab39ee67"
      },
      "source": [
        "#Mount drive to access files in gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYuEc-Nx0T2Y"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYl-eVz50bux"
      },
      "source": [
        "# read train, test dev and augemented data\n",
        "#df_train = pd.read_csv(\"/content/gdrive/MyDrive/Lakehead_NLP_Project/train.csv\")\n",
        "df_test = pd.read_csv(\"/content/gdrive/MyDrive/Lakehead_NLP_Project/dev.csv\")\n",
        "df_gold = pd.read_csv(\"/content/gdrive/MyDrive/Lakehead_NLP_Project/gold-test-27446.csv\")\n",
        "df_aug = pd.read_csv(\"/content/gdrive/MyDrive/Lakehead_NLP_Project/filtered_augemented_data.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxRvPkxs0cjj",
        "outputId": "31501c66-93ae-4b54-a3fd-91f4db86411b"
      },
      "source": [
        "# text preprocessing\n",
        "%%time\n",
        "def text_preprocessing(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"http\\S+\", \" \", text)\n",
        "  text = re.sub(' +', ' ', text)\n",
        "  \n",
        "  return text"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.25 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QwsVqyT4jWe"
      },
      "source": [
        "# Applying pre-processing on all data\n",
        "# train data\n",
        "# df_train_1 = df_train.copy()\n",
        "# df_train_1['text'] = df_train_1['text'].apply(text_preprocessing)\n",
        "\n",
        "#test data\n",
        "df_test_1 = df_test.copy()\n",
        "df_test_1['text'] = df_test_1['text'].apply(text_preprocessing)\n",
        "\n",
        "#gold data\n",
        "df_gold_1 = df_gold.copy()\n",
        "df_gold_1['text'] = df_gold_1['text'].apply(text_preprocessing)\n",
        "\n",
        "#Augemented data\n",
        "df_aug_1 = df_aug.copy()\n",
        "df_aug_1['text'] = df_aug_1['text'].apply(text_preprocessing)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IHNSByQcytE"
      },
      "source": [
        "#intializing tokenizer, fitting it on train, test, dev and augemented data and then adding padding to each sequence\n",
        "\n",
        "vocabulary_size = 20000\n",
        "maxlen = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "\n",
        "#creating vocabulary on train data\n",
        "tokenizer.fit_on_texts(df_aug_1['text'])\n",
        "\n",
        "#generating sequence of tokens on train, text, gold data\n",
        "#train_sequences = tokenizer.texts_to_sequences(df_train_1['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(df_test_1['text'])\n",
        "gold_sequences = tokenizer.texts_to_sequences(df_gold_1['text'])\n",
        "aug_sequences = tokenizer.texts_to_sequences(df_aug_1['text'])\n",
        "\n",
        "#padding the sequences\n",
        "#train_pad = pad_sequences(train_sequences, maxlen=maxlen)\n",
        "test_pad = pad_sequences(test_sequences, maxlen=maxlen)\n",
        "gold_pad = pad_sequences(gold_sequences, maxlen=maxlen)\n",
        "aug_pad = pad_sequences(aug_sequences, maxlen=maxlen)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCY-0vNn16ee"
      },
      "source": [
        "#reading glove embedding\n",
        "\n",
        "def read_glove_embedding(vocabulary_size, df, glove_path, embedding_size, tokenizer):\n",
        "\n",
        "  embeddings_index = dict()\n",
        "\n",
        "  f = open(glove_path)\n",
        "  for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "  f.close()\n",
        "  print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "  # create a weight matrix for words in training docs\n",
        "  embedding_matrix = np.zeros((vocabulary_size, embedding_size))\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "      if index > vocabulary_size - 1:\n",
        "          break\n",
        "      else:\n",
        "          embedding_vector = embeddings_index.get(word)\n",
        "          if embedding_vector is not None:\n",
        "              embedding_matrix[index] = embedding_vector\n",
        "\n",
        "  return embedding_matrix\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXySeSQ3e2Qh",
        "outputId": "b9377ebc-696a-45e3-d8a1-3a4755ad57b2"
      },
      "source": [
        "#create embedding for train data\n",
        "vocabulary_size = 20000\n",
        "df_new = df_aug_1\n",
        "glove_path = '/content/gdrive/MyDrive/Lakehead_NLP_Project/glove.6B.100d.txt'\n",
        "embedding_size = 100\n",
        "\n",
        "embedding_matrix = read_glove_embedding(vocabulary_size, df_new, glove_path,  embedding_size, tokenizer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubsAc4p2xwt9"
      },
      "source": [
        "# defining metrices to evaluate performance of model\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cfgXl9j3Yv_"
      },
      "source": [
        "#defining model\n",
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(vocabulary_size, 100, input_length=150, weights=[embedding_matrix], trainable=False))\n",
        "model_glove.add(Dropout(0.2))\n",
        "model_glove.add(Conv1D(64, 5, activation='relu'))\n",
        "model_glove.add(MaxPooling1D(pool_size=4))\n",
        "model_glove.add(LSTM(100))\n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy',f1_m, precision_m, recall_m])\n",
        "#plot_model(model_glove, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5HQyXj68aQk",
        "outputId": "4751c9f3-9aed-40f8-ad54-7118239b50ee"
      },
      "source": [
        "#summary of model\n",
        "model_glove.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 150, 100)          2000000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 150, 100)          0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 146, 64)           32064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 36, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               66000     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 2,098,165\n",
            "Trainable params: 98,165\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhS9P8Wq3aiW",
        "outputId": "0be9c166-e410-4af9-d9f1-e598c6b81053"
      },
      "source": [
        "%%time\n",
        "# fitting model on train data and validating on test data\n",
        "model_glove.fit(aug_pad, np.array(df_aug_1['is_humor']), validation_data=(test_pad, np.asarray(df_test_1['is_humor'])), epochs = 10, batch_size=128)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 150) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 150) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "85/85 [==============================] - ETA: 0s - loss: 0.5570 - binary_accuracy: 0.7081 - f1_m: 0.7995 - precision_m: 0.7103 - recall_m: 0.9307WARNING:tensorflow:Model was constructed with shape (None, 150) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 200).\n",
            "85/85 [==============================] - 51s 28ms/step - loss: 0.5564 - binary_accuracy: 0.7086 - f1_m: 0.7997 - precision_m: 0.7108 - recall_m: 0.9302 - val_loss: 0.4803 - val_binary_accuracy: 0.7730 - val_f1_m: 0.7998 - val_precision_m: 0.8920 - val_recall_m: 0.7257\n",
            "Epoch 2/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.4321 - binary_accuracy: 0.8020 - f1_m: 0.8427 - precision_m: 0.8312 - recall_m: 0.8655 - val_loss: 0.4064 - val_binary_accuracy: 0.8130 - val_f1_m: 0.8547 - val_precision_m: 0.8283 - val_recall_m: 0.8852\n",
            "Epoch 3/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.3395 - binary_accuracy: 0.8536 - f1_m: 0.8818 - precision_m: 0.8709 - recall_m: 0.8960 - val_loss: 0.3868 - val_binary_accuracy: 0.8120 - val_f1_m: 0.8513 - val_precision_m: 0.8391 - val_recall_m: 0.8660\n",
            "Epoch 4/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.3033 - binary_accuracy: 0.8668 - f1_m: 0.8932 - precision_m: 0.8853 - recall_m: 0.9046 - val_loss: 0.3816 - val_binary_accuracy: 0.8160 - val_f1_m: 0.8498 - val_precision_m: 0.8670 - val_recall_m: 0.8348\n",
            "Epoch 5/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.2698 - binary_accuracy: 0.8880 - f1_m: 0.9098 - precision_m: 0.9025 - recall_m: 0.9194 - val_loss: 0.3595 - val_binary_accuracy: 0.8260 - val_f1_m: 0.8574 - val_precision_m: 0.8785 - val_recall_m: 0.8389\n",
            "Epoch 6/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.2417 - binary_accuracy: 0.8977 - f1_m: 0.9161 - precision_m: 0.9163 - recall_m: 0.9184 - val_loss: 0.3835 - val_binary_accuracy: 0.8180 - val_f1_m: 0.8514 - val_precision_m: 0.8709 - val_recall_m: 0.8345\n",
            "Epoch 7/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.2050 - binary_accuracy: 0.9156 - f1_m: 0.9317 - precision_m: 0.9287 - recall_m: 0.9358 - val_loss: 0.5329 - val_binary_accuracy: 0.7660 - val_f1_m: 0.7806 - val_precision_m: 0.9535 - val_recall_m: 0.6616\n",
            "Epoch 8/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.2108 - binary_accuracy: 0.9144 - f1_m: 0.9299 - precision_m: 0.9337 - recall_m: 0.9310 - val_loss: 0.3759 - val_binary_accuracy: 0.8340 - val_f1_m: 0.8680 - val_precision_m: 0.8633 - val_recall_m: 0.8749\n",
            "Epoch 9/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.1717 - binary_accuracy: 0.9313 - f1_m: 0.9440 - precision_m: 0.9429 - recall_m: 0.9461 - val_loss: 0.3795 - val_binary_accuracy: 0.8290 - val_f1_m: 0.8604 - val_precision_m: 0.8785 - val_recall_m: 0.8447\n",
            "Epoch 10/10\n",
            "85/85 [==============================] - 1s 11ms/step - loss: 0.1551 - binary_accuracy: 0.9405 - f1_m: 0.9521 - precision_m: 0.9477 - recall_m: 0.9577 - val_loss: 0.3884 - val_binary_accuracy: 0.8250 - val_f1_m: 0.8609 - val_precision_m: 0.8546 - val_recall_m: 0.8699\n",
            "CPU times: user 29.7 s, sys: 1.81 s, total: 31.5 s\n",
            "Wall time: 59.7 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feb2ad67b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhl8shP23c0u",
        "outputId": "a4bade7a-a0d7-4a87-e872-7f5afb39bb57"
      },
      "source": [
        "# evaluating model on gold data\n",
        "gold_lstm_results = model_glove.evaluate(gold_pad, np.asarray(df_gold_1['is_humor']), verbose=0, batch_size=128)\n",
        "\n",
        "\n",
        "print(f'Gold Data accuracy: {gold_lstm_results[1]*100:0.2f}')\n",
        "print(f'Gold Data F1 score: {gold_lstm_results[2]}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gold Data accuracy: 82.00\n",
            "Gold Data F1 score: 0.853489875793457\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}